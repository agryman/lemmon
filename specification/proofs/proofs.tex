\documentclass[11pt, oneside]{article}

\usepackage{../shared/preamble}
\addbibresource{../shared/references.bib}

\usepackage{proofs}

\title{Proofs}
\author{Arthur Ryman, {\tt arthur.ryman@gmail.com}}
\date{\today}

\begin{document}

\maketitle

\begin{abstract}
This article is a Z Notation specification for proofs and proof checking.
It has been type checked by \fuzz.
The definitions that appear here are taken from Lemmon's book, {\it Beginning Logic}.
The purpose of this specification is to guide the development of a proof checker
aimed at Z specifications
\end{abstract}

\section{Introduction}

For a long time I have thought that it would be extremely useful to be able to write formal proofs
concerning the mathematical objects defined in Z specifications.
There are some very mature proof assistants available.
I know something about Coq, but unfortunately it's style of proof is very different from that one finds in mathematical
papers.

A Coq proof consists of applications of so-called {\it tactics}.
Each tactic represents a higher level aggregate of deductions.
This makes sense for a proof assistant since its job is to help the user discover proofs.
Tactics are like macros and as such they alleviate the user from much low-level tedium.
However, the analog of a macro in normal mathematical writing is a lemma.
Perhaps tactics are more useful for proving formal properties of programming languages where the mathematical
objects of interest are complex, but finite, recursive structures.

While a proof assistant might make sense is some contexts, proper development of a mathematical paper
consists of a gradual introduction of concepts and lemmas leading to the main results.
The proofs should, in some sense, write themselves.
The focus of a mathematical paper should be on explanation and clarity.
The proofs should be easy to read.
I'd therefore really like something that would let me write and check natural looking proofs.

In contrast to Coq, the style of proof presented by Lemmon is very clear and explicit.
However, the task of checking such a proof could easily be delegated to a program,
much the same way that \fuzz\ type checks Z.
In fact Lemmon makes that point that, although there is no mechanical way to discover proofs,
they can be mechanically checked.

I believe that the kernel of a proof checker could be very small.
It is basically an engine driven by a set of deduction rules.
The engine simply needs to check that each deduction rule gets applied correctly.
Even if it turns out that writing such an engine is too much work, the exercise of developing
at least a simple version should give me a greater appreciation of tools like Coq and enable me to
use them more productively.

My plan of attack is to formalize the concept of proof as described by Lemmon, starting with
the propositional calculus, and then move on to predicate calculus.

\section{Propositions}

The {\it propositional calculus} defines a set of formal {\it statements} or {\it propositions}
without being concerned about the subject matter described by those statements.
The only restriction on these statements is that, in any given context, 
they possess a {\it truth value} of either {\it true} or {\it false}.

A proposition is also referred to as a {\it well-formed formula} or {\it wff} for short.
This terminology stems from the traditional development of the propositional calculus in terms of
a language of sentences over an alphabet with rules that prescribe when a given sentence is {\it well-formed}.
However, here we will dispense with the language viewpoint, and its associated parsing issues, and move directly
to the end result of parsing, namely the creation of {\it abstract syntax trees} or {\it ASTs} for short.
This approach corresponds to Lemmon's Chapter 1.
He returns to the issue of formal languages in Chapter 2.

\subsection{$Prop$}


Z notation has a convenient mechanism for specifying the structure of ASTs, namely that of {\it free types}.
My first impulse was to use that mechanism to define propositions.
However, the problem with free types is that they are {it closed} in the sense that all ways of constructing members of a free type
must be specified when the free type is defined.
Lemmon's book gradually introduces ways of constructing propositions, so in the interest of following his development of the subject
as closely as possible, I won't define propositions that way.

On closer examination of free types in Z, it will be observed that they are merely syntactic sugar for introducing a new given set
along with an exhaustive set of constructors for its elements.
The constraint expressing the condition that the constructors are exhaustive is equivalent to saying that the domains of the constructors
partition the set of propositions.

Therefore, given any subset of constructors, one can define the corresponding set of propositions that can be constructed from them.
This allows new constructors to be gradually introduced.
I'll take that approach.

Let $Prop$ denote the set of all propositions.

\begin{zed}
	[Prop]
\end{zed}

\subsection{$PropVar$}

Separating of the form of a statement from its content with respect to any given subject matter is accomplished by 
the use of {\it propositional variables}. 
A propositional variable stands for an arbitrary statement that is either true or false.
Let $PropVar$ denote the set of all propositional variables.

\begin{axdef}
	PropVar: \power Prop
\end{axdef}

\subsection{\zcmd{propP}, \zcmd{propQ}, \zcmd{propR}, \zcmd{propS}, and \zcmd{propT}}

Traditionally, arbitrary statements are represented by single letters such as
$\propP$, $\propQ$, $\propR$, $\propS$, and $\propT$ which represent distinct propositions.

\begin{axdef}
	\propP, \propQ, \propR, \propS, \propT: PropVar
\where
	\disjoint \langle \{\propP\}, \{\propQ\}, \{\propR\}, \{\propS\}, \{\propT\} \rangle
\end{axdef}

\subsection{$PropLetter$}

Let $PropLetter$ denote the set of all proposition letters.

\begin{zed}
	PropLetter == \{ \propP, \propQ, \propR, \propS, \propT \}
\end{zed}

\subsection{\zcmd{propPrime}}

Typical propositions contain a small number of distinct statements, in which case the letters can be used.
If more statements occur then the letters are decorated with one or more primes, 
e.g. $\propP \propPrime$, $\propQ \propPrime \propPrime$.
Appending a prime to a propositional variable is an injection from $PropVar$ to $PropVar$.

\begin{axdef}
	\_ \propPrime: PropVar \inj PropVar
\end{axdef}

\begin{example}
$\propP \propPrime$ and $\propQ \propPrime \propPrime$ are propositional variables.
\begin{zed}
	\propP \propPrime \in PropVar
\also
	\propQ \propPrime \propPrime \in PropVar
\end{zed}

\end{example}

A propositional variable is either a letter or is primed.

\begin{zed}
	\langle PropLetter, \ran (\_ \propPrime) \rangle \partition PropVar
\end{zed}

\subsection{\zcmd{notProp} and $Negation$}

Let $A$ be a proposition.
Let $\notProp A$ denote the {\it negation} of $A$.

\begin{axdef}
	\notProp: Prop \inj Prop
\end{axdef}

\begin{example}
$\notProp \propP$ is a negation.

\begin{zed}
	\notProp \propP \in Prop
\end{zed}

\end{example}

Let $Negation$ denote the set of all negations.

\begin{zed}
	Negation == \ran \notProp
\end{zed}

\subsection{\zcmd{andProp} and $Conjunction$}

Let $A$ and $B$ be propositions.
Let $A \andProp B$ denote the {\it conjunction} of $A$ and $B$.
The conjunction $A \andProp B$ is said to have $A$ and $B$ as its {\it conjuncts}.

\begin{axdef}
	\_ \andProp \_: Prop \cross Prop \inj Prop
\end{axdef}

Let $Conjunction$ denote the set of all conjunctions.

\begin{zed}
	Conjunction == \ran (\_ \andProp \_)
\end{zed}

\subsection{\zcmd{orProp} and $Disjunction$}

Let $A$ and $B$ be propositions.
Let $A \orProp B$ denote the {\it disjunction} of $A$ and $B$.
The disjunction $A \orProp B$ is said to have $A$ and $B$ as its {\it disjuncts}.

\begin{axdef}
	\_ \orProp \_: Prop \cross Prop \inj Prop
\end{axdef}

Let $Disjunction$ denote the set of all disjunctions.

\begin{zed}
	Disjunction == \ran (\_ \orProp \_)
\end{zed}

\subsection{\zcmd{impliesProp} and $Conditional$}

Let $A$ and $B$ be propositions.
Let $A \impliesProp B$ denote the {\it conditional} of $A$ and $B$.
The conditional $A \impliesProp B$ is said to have $A$ as its  {\it antecedent} and $B$ as its {\it consequent}.

\begin{axdef}
	\_ \impliesProp \_: Prop \cross Prop \inj Prop
\end{axdef}

Let $Conditional$ denote the set of all conditionals.

\begin{zed}
	Conditional == \ran (\_ \impliesProp \_)
\end{zed}

\subsection{\zcmd{equivProp} and $Biconditional$}

Let $A$ and $B$ be propositions.
Let $A \equivProp B$ denote the {\it biconditional} of $A$ and $B$.

\begin{axdef}
	\_ \equivProp \_: Prop \cross Prop \inj Prop
\where
	\forall A, B: Prop @ \\
	\t1	A \equivProp B = (A \impliesProp B) \andProp (B \impliesProp A)
\end{axdef}

Let $Biconditional$ denote the set of all biconditionals.

\begin{zed}
	Biconditional == \ran (\_ \equivProp \_)
\end{zed}

\section{Proofs}

Lemmon has a nice way of presenting proofs.
Here's an example.

\vspace{1ex}

$\mathbf{1}\ \propP \impliesProp \propQ, \propP \vdash \propQ$

\vspace{1ex}

\begin{tabular}{l l r l l}
&	1	&	(1)	&	$\propP \impliesProp \propQ$	&	$\ruleA$ \\
&	2	&	(2)	&	$\propP$					&	$\ruleA$ \\
&	1,2	&	(3)	&	$\propQ$					&	1,2 $\ruleMPP$
\end{tabular}

\vspace{1ex}

A proof consists of a {\it sequent} to be proved and a finite sequence of one or more {\it lines}.
The lines are labelled by consecutive natural numbers, starting at $1$.

The sequent contains a, possible empty, sequence of assumptions followed by a conclusion.
The sequence of lines that follow show how the conclusion is derived from the assumptions using
various rules of derivation.

Each line of the argument contains an inference.

Each line contains a proposition and the application of the {\it proof rule} used to add it to the proof. 
A proof rule is either an {\it assumption} or a {\it derivation}.
The {\it rule of assumption} allows the addition of any proposition.
The {\it rules of derivation} allow the addition of a {\it conclusion} derived from {\it premises} that have been
previously added.
A premise is therefore either an assumption or the conclusion of a previous deduction.
Every line of the proof can therefore be traced back to a finite, possibly empty, set of assumptions upon
which it ultimately {\it depends}.

\subsection{$Sequent$ and \zcmd{sequent}}

A {\it sequent} consists of a sequence of assumptions and a conclusion.
Let $Sequent$ denote the set of all sequents.

\begin{schema}{Sequent}
	assumptions: \seq Prop \\
	conclusion: Prop
\end{schema}

Let $\sequent$ denote the binary operator that takes assumptions and a conclusion and forms a sequent.

\begin{axdef}
	\_ \sequent \_: \seq Prop \cross Prop \fun Sequent
\where
	\forall Sequent @ \\
	\t1	assumptions \sequent conclusion = \theta Sequent
\end{axdef}

\subsection{$RuleOfDerivation$}

Let $RuleOfDerivation$ denote the set of applications of rules of derviation.
In the preceeding example, $\ruleA$ and $\ruleMPP$ are names of rules of derivation.

\begin{zed}
	[RuleOfDerivation]
\end{zed}

\subsection{$Deduction$}

A {\it deduction} consists of a proposition, an application of a rule of derivation that justifies the proposition,
and a finite, possibly empty, set of assumptions on which the proposition depends.
Let $Deduction$ denote the set of all deduction.

\begin{schema}{Deduction}
	assumptions: \finset \nat_1 \\
	prop: Prop \\
	rule: RuleOfDerivation
\end{schema}

\subsection{$DeductionTuple$}

Let $DeductionTuple$ denote the tuple formed by the components of a deduction.

\begin{zed}
	DeductionTuple == \finset \nat_1 \cross Prop \cross RuleOfDerivation
\end{zed}

\subsection{\zcmd{deductionTuple}}

Let $\deductionTuple$ denote the function that maps a deduction to its tuple.

\begin{zed}
	\deductionTuple == (\lambda Deduction @ (assumptions, prop, rule))
\end{zed}

\begin{remark}
The mapping from deductions to tuples is a bijection.

\begin{zed}
	\deductionTuple \in Deduction \bij DeductionTuple
\end{zed}

\end{remark}

\subsection{\zcmd{deductionProp}}

Let $\deductionProp$ denote the function that maps a deduction tuple to its $prop$ component.

\begin{zed}
	\deductionProp == \{~ Deduction @ (assumptions, prop, rule) \mapsto prop ~\}
\end{zed}

\subsection{$Argument$}

An {\it argument} is a finite sequence of deductions.
Let $Argument$ denote the set of all arguments.

\begin{zed}
	Argument == \seq DeductionTuple
\end{zed}

\subsection{$ArgumentDeduction$}

When determining the soundness of an argument, we need to check of the soundness of each deduction.
Each deduction within an argument is uniquely identified by its line number.
Let $ArgumentDeduction$ denote the set of all arguments and valid line numbers in them.

\begin{schema}{ArgumentDeduction}
	argument: Argument \\
	lineNumber: \nat_1 \\
	Deduction
\where
	lineNumber \in \dom argument
\also
	argument(lineNumber) = (assumptions, prop, rule)
\end{schema}
\begin{itemize}
	\item The deduction is identified by its line number within the argument.
	\item The deduction has a tuple of components.
\end{itemize}

\subsection{$SoundDeduction$}

A deduction within an argument is sound if it adheres to one of the rules of derivation.
The rules of derivation will be described below.
Let $SoundDeduction$ denote the set of all sound deductions.

\begin{axdef}
	SoundDeduction: \power ArgumentDeduction
\end{axdef}

\subsection{$SoundArgument$}

An argument is sound precisely when all of its deductions are sound.
Let $SoundArgument$ denote the set of all sound arguments.

\begin{axdef}
	SoundArgument: \power Argument
\end{axdef}

\subsection{\zcmd{deductionSequent}}

Every deduction in an argument defines a sequent.
Let $\deductionSequent$ denote the mapping from deductions to sequents.

\begin{axdef}
	\deductionSequent: ArgumentDeduction \fun Sequent
\where
	\forall ArgumentDeduction @ \\
	\t1	\deductionSequent(\theta ArgumentDeduction) = \\
	\t2		assumptions \extract (argument \comp \deductionProp) \sequent prop
\end{axdef}

\subsection{$ArgumentProvesSequent$}

A sound argument proves a sequent if the final deduction of the argument defines the given sequent.
Let $ArgumentProvesSequent$ denote this situation.

\begin{schema}{ArgumentProvesSequent}
	ArgumentDeduction \\
	s: Sequent
\where
	argument \in SoundArgument
\also
	lineNumber = \# argument
\also
	s = \deductionSequent(\theta ArgumentDeduction)
\end{schema}

\subsection{$Proof$}

A proof is a sequent and a sound argument whose last deduction proves the sequent.
Let $Proof$ denote the set of proofs.

\begin{axdef}
	Proof: Sequent \rel SoundArgument
\where
	Proof = \{~ ArgumentDeduction | \\
	\t1	(lineNumber = \# argument \land \\
	\t1	argument \in SoundArgument) @ \\
	\t2		\deductionSequent(\theta ArgumentDeduction) \mapsto argument ~\}
\end{axdef}


\subsection{\zcmd{ruleA}}

Let $\ruleA$ denote the rule of assumption.
The rule of assumption is used to introduce an arbitrary assumption at any point in the argument.

\begin{axdef}
	\ruleA: RuleOfDerivation
\end{axdef}

\subsection{$RuleOfAssumptionDetail$}

A deduction uses the rule of assumption $\ruleA$ in an argument is sound if it introduces some arbitrary proposition $P$ and
it depends only on itself.
Let $RuleOfAssumptionDetail$ denote the set of all deductions, along with their details, that use the rule of assumption soundly.

\begin{schema}{RuleOfAssumptionDetail}
	ArgumentDeduction \\
	P: Prop
\where
	assumptions = \{ lineNumber \}
\also
	prop = P
\also
	rule = \ruleA
\end{schema}

\begin{itemize}
	\item The deduction depends only on itself.
	\item The deduction introduces an arbitrary proposition $P$.
	\item The deduction is justified by the rule of assumption $\ruleA$.
\end{itemize}

\subsection{$RuleOfAssumption$}

Let $RuleOfAssumption$ denote the set of all deductions that use the rule of assumption with the detail hidden.

\begin{zed}
	RuleOfAssumption \defs RuleOfAssumptionDetail \project ArgumentDeduction
\end{zed}

The rule of assumption is sound.

\begin{zed}
	RuleOfAssumption \subset SoundDeduction
\end{zed}

\subsection{\zcmd{ruleMPP}}

Let $\ruleMPP$ denote the MPP rule.
The MPP rule is used to deduce the consequent of a conditional given its antecedent.
The rule specifies the conditional and antecedent as its premises.

\begin{axdef}
	\ruleMPP: \nat_1 \cross \nat_1 \fun RuleOfDerivation
\end{axdef}

\subsection{$RuleOfMPPDetail$}

A deduction that uses the rule $\ruleMPP(i, j)$ in an argument is sound if $i$ and $j$ are lines
that precede it, the proposition on line $i$ is an implication, the proposition on line $j$ is the antecedent
of the implication, the proposition of the proof line is the consequent of the implication,
and the proof line's assumptions is the union of the assumptions of lines $i$ and $j$.
Let $RuleOfMPPDetail$ denote the set of all deductions, along with their detail, that use the rule of MPP soundly.

\begin{schema}{RuleOfMPPDetail}
	ArgumentDeduction \\
	i, j: \nat_1 \\
	Deduction_1 \\
	Deduction_2 \\
	P, Q: Prop
\where
	rule =  \ruleMPP(i, j)
\also
	i < lineNumber \land j < lineNumber
\also
	argument(i) = (assumptions_1, P \impliesProp Q, rule_1)
\also
	argument(j) = (assumptions_2, P, rule_2)
\also
	assumptions = assumptions_1 \cup assumptions_2
\also
	prop = Q
\end{schema}

\begin{itemize}
	\item The rule of derivation is $\ruleMPP$ which specifies the premise line numbers $i$ of a conditional and $j$ of its antecedent.
	\item The line numbers of the conditional and its antecedent must precede the deduction in the argument.
	\item Line number $i$ contains a conditional of the form $P \impliesProp Q$.
	\item Line number $j$ contains the antecedent $P$ of the conditional.
	\item The deduction depends on the union of the assumptions that the premises depend on.
	\item The deduction introduces the consequent $Q$ as the conclusion of the premises.
\end{itemize}

\subsection{$RuleOfMPP$}

Let $RuleOfMPP$ denote the set of all deductions that use the rule of MPP with the detail hidden.

\begin{zed}
	RuleOfMPP \defs RuleOfMPPDetail \project ArgumentDeduction
\end{zed}

The rule of MPP is sound.

\begin{zed}
	RuleOfMPP \subset SoundDeduction
\end{zed}

\subsection{$argument_1$}

Let $argument_1$ denote the argument defined by proof $\mathbf{1}$.

\begin{zed}
	argument_1 == \\
	\t1	\{ 1 \mapsto (\{ 1\}, \propP \impliesProp \propQ, \ruleA), \\
	\t1	2 \mapsto (\{ 2 \}, \propP, \ruleA), \\
	\t1	3 \mapsto (\{ 1, 2 \}, \propQ, \ruleMPP(1,2)) \}
\end{zed}

\begin{example}
$argument_1$ is an argument.

\begin{zed}
	argument_1 \in Argument
\end{zed}

\end{example}

\begin{example}
Line 3 of proof $\mathbf{1}$ corresponds to the following deduction tuple.

\begin{zed}
	(\{ 1, 2 \}, \propQ, \ruleMPP(1,2)) \in DeductionTuple
\end{zed}

\end{example}

\subsection{$proof_2$}

Here is Lemmon's proof $\mathbf{2}$.

\vspace{1ex}

$\mathbf{2}\ \notProp \propQ \impliesProp (\notProp \propP \impliesProp \propQ), \notProp \propQ \vdash \notProp \propP \impliesProp \propQ$

\vspace{1ex}

\begin{tabular}{l l r l l}
&	1	&	(1)	&	$\notProp \propQ \impliesProp (\notProp \propP \impliesProp \propQ)$	&	$\ruleA$ \\
&	2	&	(2)	&	$\notProp \propQ$											&	$\ruleA$ \\
&	1,2	&	(3)	&	$ \notProp \propP \impliesProp \propQ$							&	1,2 $\ruleMPP$
\end{tabular}

\vspace{1ex}

Let $sequent_2$ denote the sequent of this proof.

\begin{zed}
	sequent_2 == \langle \notProp \propQ \impliesProp (\notProp \propP \impliesProp \propQ),  \notProp \propQ \rangle \sequent \notProp \propP \impliesProp \propQ
\end{zed}

Let $argument_2$ denote the argument of this proof.

\begin{zed}
	argument_2 == \\
	\t1	\{ 1 \mapsto (\{ 1\}, \notProp \propQ \impliesProp (\notProp \propP \impliesProp \propQ), \ruleA), \\
	\t1	2 \mapsto (\{ 2 \}, \notProp \propQ, \ruleA), \\
	\t1	3 \mapsto (\{ 1, 2 \}, \notProp \propP \impliesProp \propQ, \ruleMPP(1,2)) \}
\end{zed}

Let $proof_2$ denote this proof.

\begin{zed}
	proof_2 ==  (sequent_2, argument_2)
\end{zed}

\begin{example}
$proof_2$ is a proof.

\begin{zed}
	proof_2 \in Proof
\end{zed}

\end{example}

\section{The Curry-Howard Correspondence}

The {\it Curry-Howard Correspondence} is an interpretation of propositions and proofs in terms of types.
To each proposition there correspondences a type.
The inhabitants of the type that corresponds to a proposition are proofs of that proposition.
The logical connectives that build up propositions correspond to type constructors.

To illustrate the correspondence, consider the implication logical connective $P \implies Q$.
It corresponds to the type constructor $P \fun Q$.
A proof $f$ of $P \implies Q$ corresponds to a function that maps any proof of $P$ to some proof of $Q$.

Of course, $P \fun Q$ is not a type in Z. 
It is a subset of the type $\power(P \cross Q)$.
Nevertheless, we'll press on and pretend that it is a Z type for now.

The rules of derivation correspond to the construction of a proof from assumptions.
For example the rule of MPP corresponds to function application.
Consider $Proof_1$.
It corresponds to the following.

\begin{schema}{CHProof1}[P,Q]
	f: P \fun Q \\
	x: P \\
	y: Q
\where
	y = f(x)
\end{schema}

\printbibliography

\end{document}